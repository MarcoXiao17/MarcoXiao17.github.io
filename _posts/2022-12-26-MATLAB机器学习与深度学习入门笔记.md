近日通过MATLAB Onramp课程简要入门了机器学习与深度学习，我将这篇笔记简要阐述机器学习与深度学习的基础要点。

# 学习前的准备:数据的准备与清洗
准备数据:需要对获得的数据进行格式化与清洗。

一般情况下，进行机器学习前，我们需要将数据转换为特点的集合。例如，进行手写识别时，我们需要计算每个手写字符对应的长宽比，将连续的手写落笔点数据转化为x/y轴坐标-时间关系图，并尝试在这个关系图中再发现某些数据特征。由于我们获取到数据来源不一，我们还应当对数据进行格式化操作，例如将每个手写数据的边界重叠。

一般情况下，我们可以使用矩阵运算来对数据进行格式化。注意的是如果要以普通的四则运算进行非同维度矩阵的乘除操作，需要在运算符前加.，如./
而在进行机器学习时，我们将所需学习的数据直接以Array的矩阵的方式放进模型进行推算。

注意的是，我们一般在数据中，分出一些已标记好的数据专用于进行验证(Test)
->使用函数:

- datastore

在MATLAB中，我们可以使用datastore进行数据的储存。

datastore的创建语法: `ds=datastore(location,name,value)`

创建一个包含当前文件夹所有jpg文件的datastore:

`ds=imageDatastore("*.jpg","IncludeSubfolders",true,"LabelSource","foldernames")`

提取当前datastore的文件名列表

`ds.Files`

获取当前datastore中的第n个图片

`f=readimage(ds,n)`

datastore中数据的转化与储存:

对于单张图片，我们可以使用imresize(`img=imresize(img[x y])`)

而对于一个datastore中的所有图片，我们可以使用augmentedImageDatastore

`newds=augmentedImageDatastore([x y],ds,[params])`

params中，可以进行黑白到彩色的转化(`"ColorPreprocessing","gray2rgb"`)等操作。

有时，我们将通过一般datastore来储存一般数据。

`ds=datastore("*.xlsx")`->把工作文件夹下*.xlsx全部储存至datastore中

`data=import(ds)`->导入某个datastore中的全部数据

`transform(datastore,@functionname)`->用functionname对datastore内容进行变形

`data=readall(ds)`->读入ds中所有数据

-函数

在MATLAB中，我们可以定义函数。

    function outputvar=functionname(inputvar1)

        code block

    end

# 学习:机器学习

机器学习的核心是以各种公式拟合对离散的数据点进行归类。比如K Nearest Neighbor算法，就是将空间某区标记为此点最近k个数据点中出现最多的类型对应分类。

我们一般使用各模型对应的fit函数进行拟合。

例如knn：

`knnmodel=fitcknn(data,target,[params])`
其中，params可以指定N值:'NumNeighbors','1'

然后进行预测

`a=predict(model,newdata)`

# 学习:深度学习

深度学习是使用数据集对某个模型进行训练的过程。

首先，我们应当根据我们的学习任务，确定我们需要使用到的模型。

一般情况下，一个深度学习模型具有多个*层*，每个层具有该层的属性与连接方式。一般情况下，*权重*是一个层的重要属性。一个完整的*模型*，就是由一个个层以不同的权重和连接途径组成的。在通过修改已建好的模型进行的Transfer Learning中，我们一般关注输入/输出与数个与结果表示相关的对应层并修改，保持中间大部分结构不变。我们可以在Deep Network Designer中快速设计或修改网络并导出。`load untrainedNetwork`（？）

在训练一个模型时，有时有多个具体的训练方法。我们应当合理选择训练方法与训练参数。

获取当前训练方法的训练参数:`opts = trainingOptions("method","Name",value)`,其中，method有多做那个方法可选，如"sgdm","adam",后面部分用于更改某个参数并override默认值。

最后便是训练:

`[targetnetwork, info] = trainNetwork(data,lgraph,opts)`

其中，lgraph用于生成过程表格

最后便可进行预测`a=predict(model,newdata)`

# 验证：是否能够准确分类？

一般情况下，我们使用predict/classify得出的结论是一个一维array。所以，我们可以使用confusion chart`confusionchart(x,y)`来图形化地观察正确与错误分类。有时，我们能使用nnz函数统计正确分类的个数。

如果分类准确，那么该模型即可投入生产；否则，我们将更改模型或训练参数。例如

"NumNeighbors"-knn

"InitialLearnRate"(一般调小) "Momentum" - DNN

常见的错误原因:overfitting（模型学习了太多**训练数据**的特征，而不是实际特征)
